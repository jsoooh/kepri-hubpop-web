heat_template_version: '2018-08-31'

description: hadoop singleMaster template

parameter_groups:
- parameters:
  - image
  - master_flavor
  - worker_flavor
  - master_cnt
  - worker_cnt
  - availability_zone
  - key_name
  - provider_net
  - root_password
  - security_group
  - api_end_point
  - provider_subnet
  - hive_password
  - private_key

parameters:
  image:
    label: "이미지"
    type: string
  availability_zone:
    label: "가용구역"
    type: string
  master_flavor:
    type: string
  master_cnt:
    type: string
  worker_cnt:
    type: string
  worker_flavor:
    type: string
  key_name:
    label: "보안키"
    type: string
  provider_net:
    label: "provider_net"
    type: string
  api_end_point:
    label: "api_end_point"
    type: string
  provider_subnet:
    label: "provider_subnet"
    type: string
  security_group:
    label: "security_group"
    type: string
    default: default
  root_password:
    label: "root_password"
    type: string
  hive_password:
    label: "hive_password"
    type: string
  private_key:
    label: "private_key"
    type: string

resources:

  server1_port:
    type: OS::Neutron::Port
    properties:
      fixed_ips: [{ subnet_id: { get_param: provider_subnet } }]
      network: { get_param: provider_net }
      security_groups: [{ get_param: security_group }]

  {% set iworkerCnt = workerCnt|int %}  {# string으로 받아서 추가 #}
  {% set pworker =  iworkerCnt + 1 %}
  {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}

  server{{server}}_port:
    type: OS::Neutron::Port
    properties:
      fixed_ips: [{ subnet_id: { get_param: provider_subnet } }]
      network: { get_param: provider_net }
      security_groups: [{ get_param: security_group }]

  {%- endfor %}

  init_config1:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config:
        str_replace:
          params:
            $api_end_point: { get_param: api_end_point }
            $project_id: { get_param: 'OS::project_id' }
            $stack_id: { get_param: 'OS::stack_id' }
            $stack_name: { get_param: 'OS::stack_name' }
            $private_key: { get_param: private_key }
            $root_password: { get_param: root_password }
            $hive_password: { get_param: hive_password }
            $master_address: { get_attr: [server1_port, fixed_ips, 0, ip_address] }
            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            $node{{worker}}_address: { get_attr: [server{{server}}_port, fixed_ips, 0, ip_address] }
            {%- endfor %}
            $server_addresses:
              list_join:
                - ','
                - - { get_attr: [server1_port, fixed_ips, 0, ip_address] }
                  {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
                  - { get_attr: [server{{server}}_port, fixed_ips, 0, ip_address] }
                  {%- endfor %}
          template: |
            #!/bin/sh
            echo "01.hadoop SingleMaster msater install start ......7"

            curl -X PUT -H "Content-Type: application/json" --connect-timeout 10 --data "{\"deployStatus\": \"DEPLOY_IN_PROGRESS\"}" $api_end_point/vm_catalog/external/$project_id/deploy/$stack_name/$stack_id/status

            cat <<EOF>> /etc/ssh/ssh_config
            Port 20022
            EOF

            sudo service sshd restart


            cat <<EOF> /home/centos/.ssh/kepri-msa_default.pem
            $private_key
            EOF

            chown centos.centos /home/centos/.ssh/kepri-msa_default.pem
            chmod 600 /home/centos/.ssh/kepri-msa_default.pem

            echo "address1=$master_address"
            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            echo "address{{server}}=$node{{worker}}_address"
            {%- endfor %}

            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            masterRun=1
            while [[ masterRun -eq 1 ]]
            do
              echo "nc -z $node{{worker}}_address 20022"
              nc -z $node{{worker}}_address 20022
              masterRun=$?
              sleep 5
            done
            echo "node{{worker}} active"
            {%- endfor %}

            echo "##### 01.hadoop core setting start ###########"
            echo "[01] host setting"
            echo "##### 01.1 host file setting ###########"
            cat <<EOF>> /etc/hosts
            $master_address hmaster
            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            $node{{worker}}_address hworker-{{worker}}
            {%- endfor %}
            EOF

            sudo -i -u centos bash << EOF
            source ~/.bashrc
            mkdir -p /home/centos/hadoop/pids
            mkdir -p /home/centos/hadoop/etc/hadoop/dfs/data
            mkdir -p /home/centos/hadoop/etc/hadoop/dfs/name
            sudo chmod 755 /home/centos/hadoop/pids
            sudo chmod 755 /home/centos/hadoop/etc/hadoop/dfs/data
            sudo chmod 755 /home/centos/hadoop/etc/hadoop/dfs/name
            EOF

            sudo -i -u centos bash << EOF
            source ~/.bashrc
            echo "##### 01.2 add_known_hosts ###########"
            ssh-keyscan -p 20022 localhost,0.0.0.0 >> /home/centos/.ssh/known_hosts
            ssh-keyscan -p 20022 hmaster,$master_addres >> /home/centos/.ssh/known_hosts
            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            ssh-keyscan -p 20022 hworker-{{worker}},$node{{worker}}_address >> /home/centos/.ssh/known_hosts
            {%- endfor %}
            EOF

            sudo -i -u centos bash << EOF
            source ~/.bashrc
            echo "##### 01.3 add_authorized_keys ###########"
            ssh-keygen -b 2048 -t rsa -f /home/centos/.ssh/id_rsa -q -N ''
            cat /home/centos/.ssh/id_rsa.pub | ssh -i "/home/centos/.ssh/kepri-msa_default.pem" centos@localhost  "cat - >> /home/centos/.ssh/authorized_keys"
            cat /home/centos/.ssh/id_rsa.pub | ssh -i "/home/centos/.ssh/kepri-msa_default.pem" centos@hmaster  "cat - >> /home/centos/.ssh/authorized_keys"
            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            cat /home/centos/.ssh/id_rsa.pub | ssh -i "/home/centos/.ssh/kepri-msa_default.pem" centos@hworker-{{worker}}  "cat - >> /home/centos/.ssh/authorized_keys"
            {%- endfor %}
            EOF

            echo "[01]hadoop config file update"
            cat <<EOF>> /home/centos/hadoop/etc/hadoop/core-site.xml
            <configuration>
                    <property>
                        <name>fs.default.name</name>
                        <value>hdfs://hmaster:9000</value>
                    </property>
            </configuration>
            EOF

            cat <<EOF>> /home/centos/hadoop/etc/hadoop/hdfs-site.xml
            <configuration>
                <property>
                    <name>dfs.replication</name>
                    <value>1</value>
                </property>
                <property>
                    <name>dfs.name.dir</name>
                    <value>/home/centos/hadoop/etc/hadoop/dfs/data</value>
                </property>
                <property>
                    <name>dfs.data.dir</name>
                    <value>/home/centos/hadoop/etc/hadoop/dfs/name</value>
                </property>
                <property>
                    <name>dfs.namenode.checkpoint.dir</name>
                    <value>/home/centos/hadoop/etc/hadoop/dfs/namesecondary</value>
                </property>
                <property>
                    <name>dfs.permissions</name>
                    <value>true</value>
                </property>
            </configuration>
            EOF

            cat <<EOF>> /home/centos/hadoop/etc/hadoop/mapred-site.xml
            <configuration>
                <property>
                    <name>dfs.replication</name>
                    <value>1</value>
                </property>
                <property>
                    <name>dfs.name.dir</name>
                    <value>/home/centos/hadoop/etc/hadoop/dfs/data</value>
                </property>
                <property>
                    <name>dfs.data.dir</name>
                    <value>/home/centos/hadoop/etc/hadoop/dfs/name</value>
                </property>
                <property>
                  <name>dfs.namenode.checkpoint.dir</name>
                  <value>/home/centos/hadoop/etc/hadoop/dfs/namesecondary</value>
                </property>
                <property>
                    <name>dfs.permissions</name>
                    <value>true</value>
                </property>
            </configuration>
            EOF

            cat <<EOF>> /home/centos/hadoop/etc/hadoop/yarn-site.xml
            <configuration>
            <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
            </property>
            <property>
                <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
            <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>
            <property>
                <name>yarn.resourcemanager.hostname</name>
                <value>hmaster</value>
            </property>
            <property>
                <name>yarn.application.classpath</name>
                <value>
                    /home/centos/hadoop/etc/hadoop,
                    /home/centos/hadoop/share/hadoop/common/*,
                    /home/centos/hadoop/share/hadoop/common/lib/*,
                    /home/centos/hadoop/share/hadoop/hdfs/*,
                    /home/centos/hadoop/share/hadoop/hdfs/lib/*,
                    /home/centos/hadoop/share/hadoop/mapreduce/*,
                    /home/centos/hadoop/share/hadoop/mapreduce/lib/*,
                    /home/centos/hadoop/share/hadoop/yarn/*,
                    /home/centos/hadoop/share/hadoop/yarn/lib/*
                </value>
            </property>
            </configuration>
            EOF

            echo "----------config file set end"

            sudo -- sh -c "echo hworker-1 > /home/centos/hadoop/etc/hadoop/slaves"
            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            sudo -- sh -c "echo hworker-{{worker}} >> /home/centos/hadoop/etc/hadoop/slaves"
            {%- endfor %}

            echo "#####[02]hdfs namenode -format#####"
            sudo su - centos -c "hadoop namenode -format -force "
            echo "##### [02].hdfs namenode -format ###########"

            echo "#####[03] start-dfs #####"
            sudo su - centos -c "start-dfs.sh "
            echo "##### [03].start-dfs end ###########"

            echo "#####[04]start-yarn #####"
            sudo su - centos -c "start-yarn.sh "
            echo "##### [04].start-dfs end ###########"

{% if sparkUse %}
            sudo -i -u centos bash << EOF
            source ~/.bashrc
            echo "##### 02.spark setting start ###########"
            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            sudo -- sh -c "echo hworker-{{worker}} >> /home/centos/spark/conf/slaves"
            {%- endfor %}
            /home/centos/spark/sbin/start-master.sh
            echo "##### 02.spark setting end ###########"
            EOF
{% endif %}

{% if hbaseUse %}
            sudo -i -u centos bash << EOF
            source ~/.bashrc
            echo "##### 03.zookeeper setting start ###########"
            mkdir /home/centos/zookeeper/tmp
            cp /home/centos/zookeeper/conf/zoo_sample.cfg /home/centos/zookeeper/conf/zoo.cfg
            sudo -- sh -c "echo dataDir=/home/centos/zookeeper/tmp >> /home/centos/zookeeper/conf/zoo.cfg"
            sudo -- sh -c "echo server.1=hmaster:2888:3888 >> /home/centos/zookeeper/conf/zoo.cfg"
            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            sudo -- sh -c "echo server.{{server}}=hworker-{{worker}}:2888:3888 >> /home/centos/zookeeper/conf/zoo.cfg"
            {%- endfor %}
            echo "1" > /home/centos/zookeeper/tmp/myid
            chown centos:centos /home/centos/zookeeper/tmp/myid
            chmod 777 /home/centos/zookeeper/tmp/myid
            EOF
            sudo -i -u centos bash << EOF
            source ~/.bashrc
            /home/centos/zookeeper/bin/zkServer.sh start
            echo "##### 03.zookeeper setting end ###########"
            EOF

            {% for worker in range(1,pworker) %} {% set server = worker + 1 %}
            masterRun=1
            while [[ masterRun -eq 1 ]]
            do
              echo "nc -z $node{{worker}}_address 3888"
              nc -z $node{{worker}}_address 3888
              masterRun=$?
              sleep 5
            done
            echo "zookeeper node{{worker}} active"
            {% endfor %}


            echo "##### 04.hbase setting start ###########"
            VAR1=$(cat <<EOF
            <?xml version="1.0"?>
            <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
            <configuration>
                <property>
                    <name>hbase.rootdir</name>
                    <value>hdfs://hmaster:9000/hbase</value>
                </property>
                <property>
                    <name>hbase.cluster.distributed</name>
                    <value>true</value>
                </property>
                <property>
                    <name>hbase.zookeeper.quorum</name>
                    <value>hmaster{%- for worker in range(1,pworker) %}{% set server = worker + 1 %},hworker-{{worker}}{%- endfor %}</value>
                </property>
                <property>
                    <name>dfs.replication</name>
                    <value>3</value>
                </property>
                <property>
                  <name>hbase.unsafe.stream.capability.enforce</name>
                  <value>false</value>
                </property>
                <property>
                    <name>hbase.zookeeper.property.clientPort</name>
                    <value>2181</value>
                </property>
            </configuration>
            EOF
            )

            cat <<EOF> /home/centos/hbase/conf/hbase-site.xml
            ${VAR1}
            EOF

            chown centos:centos /home/centos/hbase/conf/hbase-site.xml

            cat <<EOF> /home/centos/hbase/conf/regionservers
            hmaster
            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            hworker-{{worker}}
            {%- endfor %}
            EOF

            chown centos:centos /home/centos/hbase/conf/regionservers

            cat <<EOF>> /home/centos/hbase/conf/hbase-env.sh
            export HBASE_MANAGES_ZK=false
            export HBASE_PID_DIR=/home/centos/hbase/pid
            EOF


            sudo -i -u centos bash << EOF
            source ~/.bashrc
            hadoop dfsadmin -safemode leave
            /home/centos/hbase/bin/start-hbase.sh
            EOF

            echo "##### 04.hbase setting end ###########"
{% endif %}

            echo "##### [05]hive setting start ###########"
            echo "mariadb setting start"
            #cp /etc/my.cnf /etc/my.cnf.backup
            #sed -i 's/^port            = 3306/port            = $service_port/' /etc/my.cnf
            sleep 1
            systemctl start mariadb
            /usr/bin/mysqladmin -u root password '$root_password'

            mysql -u root -p$root_password <<EOF
            create database hive CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;
            GRANT ALL PRIVILEGES ON hive.* To 'hive'@LOCALHOST IDENTIFIED BY '$hive_password';
            EOF

            sudo systemctl enable mariadb
            echo "mariadb setting end"

            cat <<EOF> /home/centos/hive/conf/hive-site.xml
            <?xml version="1.0" encoding="UTF-8" standalone="no"?>
            <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
            <configuration>
                <property>
                    <name>hive.metastore.local</name>
                    <value>false</value>
                </property>
                <property>
                    <name>javax.jdo.option.ConnectionURL</name>
                    <value>jdbc:mariadb://localhost:3306/hive?createDatabaseIfNotExist=true</value>
                </property>
                <property>
                    <name>javax.jdo.option.ConnectionDriverName</name>
                    <value>org.mariadb.jdbc.Driver</value>
                </property>
                <property>
                    <name>javax.jdo.option.ConnectionUserName</name>
                    <value>hive</value>
                </property>
                <property>
                    <name>javax.jdo.option.ConnectionPassword</name>
                    <value><![CDATA[$hive_password]]></value>
                </property>
            </configuration>
            EOF

            chown centos:centos /home/centos/hive/conf/hive-site.xml
            echo "## MariaDB connetc init "
            sudo su - centos -c "/home/centos/hive/bin/schematool -initSchema -dbType mysql "
            echo "##### [05]hive setting end ###########"

            curl -X PUT -H "Content-Type: application/json" --connect-timeout 10 --data "{\"deployStatus\": \"DEPLOY_COMPLETE\"}" $api_end_point/vm_catalog/external/$project_id/deploy/$stack_name/$stack_id/status

  {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
  init_config{{server}}:
    type: OS::Heat::SoftwareConfig
    properties:
      group: ungrouped
      config:
        str_replace:
          params:
            $api_end_point: { get_param: api_end_point }
            $project_id: { get_param: 'OS::project_id' }
            $stack_id: { get_param: 'OS::stack_id' }
            $stack_name: { get_param: 'OS::stack_name' }
            $private_key: { get_param: private_key }
            $root_password: { get_param: root_password }
            $master_address: { get_attr: [server1_port, fixed_ips, 0, ip_address] }
            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            $node{{worker}}_address: { get_attr: [server{{server}}_port, fixed_ips, 0, ip_address] }
            {%- endfor %}
            $server_addresses:
              list_join:
                - ','
                - - { get_attr: [server1_port, fixed_ips, 0, ip_address] }
                  {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
                  - { get_attr: [server{{server}}_port, fixed_ips, 0, ip_address] }
                  {%- endfor %}
          template: |
            #!/bin/sh
            echo "hadoop{{server}} SingleMaster worker{{server}}  install start"

            cat <<EOF>> /etc/ssh/ssh_config
            Port 20022
            EOF

            sudo service sshd restart


            cat <<EOF> /home/centos/.ssh/kepri-msa_default.pem
            $private_key
            EOF

            chown centos.centos /home/centos/.ssh/kepri-msa_default.pem
            chmod 600 /home/centos/.ssh/kepri-msa_default.pem

            echo "[01] host setting"
            echo "##### 01.1 host file setting ###########"
            cat <<EOF>> /etc/hosts
            $master_address hmaster
            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            $node{{worker}}_address hworker-{{worker}}
            {%- endfor %}
            EOF

            sudo -i -u centos bash << EOF
            source ~/.bashrc
            mkdir -p /home/centos/hadoop/pids
            mkdir -p /home/centos/hadoop/etc/hadoop/dfs/data
            mkdir -p /home/centos/hadoop/etc/hadoop/dfs/name
            sudo chmod 755 /home/centos/hadoop/pids
            sudo chmod 755 /home/centos/hadoop/etc/hadoop/dfs/data
            sudo chmod 755 /home/centos/hadoop/etc/hadoop/dfs/name
            EOF

            sudo -i -u centos bash << EOF
            source ~/.bashrc
            echo "##### 01.2 add_known_hosts ###########"
            ssh-keyscan -p 20022 hmaster,$master_addres >> /home/centos/.ssh/known_hosts
            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            ssh-keyscan -p 20022 hworker-{{worker}},$node{{worker}}_address >> /home/centos/.ssh/known_hosts
            {%- endfor %}
            EOF

            sudo -i -u centos bash << EOF
            source ~/.bashrc
            echo "##### 01.3 add_authorized_keys ###########"
            ssh-keygen -b 2048 -t rsa -f /home/centos/.ssh/id_rsa -q -N ''
            cat /home/centos/.ssh/id_rsa.pub | ssh -i "/home/centos/.ssh/kepri-msa_default.pem" centos@hmaster  "cat - >> /home/centos/.ssh/authorized_keys"
            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            cat /home/centos/.ssh/id_rsa.pub | ssh -i "/home/centos/.ssh/kepri-msa_default.pem" centos@hworker-{{worker}}  "cat - >> /home/centos/.ssh/authorized_keys"
            {%- endfor %}
            EOF

            echo "[01]hadoop config file update"
            cat <<EOF>> /home/centos/hadoop/etc/hadoop/core-site.xml
            <configuration>
                    <property>
                        <name>fs.default.name</name>
                        <value>hdfs://hmaster:9000</value>
                    </property>
            </configuration>
            EOF

            cat <<EOF>> /home/centos/hadoop/etc/hadoop/hdfs-site.xml
            <configuration>
                <property>
                    <name>dfs.replication</name>
                    <value>1</value>
                </property>
                <property>
                    <name>dfs.name.dir</name>
                    <value>/home/centos/hadoop/etc/hadoop/dfs/data</value>
                </property>
                <property>
                    <name>dfs.data.dir</name>
                    <value>/home/centos/hadoop/etc/hadoop/dfs/name</value>
                </property>
                <property>
                    <name>dfs.namenode.checkpoint.dir</name>
                    <value>/home/centos/hadoop/etc/hadoop/dfs/namesecondary</value>
                </property>
                <property>
                    <name>dfs.permissions</name>
                    <value>true</value>
                </property>
            </configuration>
            EOF

            cat <<EOF>> /home/centos/hadoop/etc/hadoop/mapred-site.xml
            <configuration>
                <property>
                    <name>dfs.replication</name>
                    <value>1</value>
                </property>
                <property>
                    <name>dfs.name.dir</name>
                    <value>/home/centos/hadoop/etc/hadoop/dfs/data</value>
                </property>
                <property>
                    <name>dfs.data.dir</name>
                    <value>/home/centos/hadoop/etc/hadoop/dfs/name</value>
                </property>
                <property>
                  <name>dfs.namenode.checkpoint.dir</name>
                  <value>/home/centos/hadoop/etc/hadoop/dfs/namesecondary</value>
                </property>
                <property>
                    <name>dfs.permissions</name>
                    <value>true</value>
                </property>
            </configuration>
            EOF

            cat <<EOF>> /home/centos/hadoop/etc/hadoop/yarn-site.xml
            <configuration>
            <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
            </property>
            <property>
                <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
            <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>
            <property>
                <name>yarn.resourcemanager.hostname</name>
                <value>hmaster</value>
            </property>
            <property>
                <name>yarn.application.classpath</name>
                <value>
                    /home/centos/hadoop/etc/hadoop,
                    /home/centos/hadoop/share/hadoop/common/*,
                    /home/centos/hadoop/share/hadoop/common/lib/*,
                    /home/centos/hadoop/share/hadoop/hdfs/*,
                    /home/centos/hadoop/share/hadoop/hdfs/lib/*,
                    /home/centos/hadoop/share/hadoop/mapreduce/*,
                    /home/centos/hadoop/share/hadoop/mapreduce/lib/*,
                    /home/centos/hadoop/share/hadoop/yarn/*,
                    /home/centos/hadoop/share/hadoop/yarn/lib/*
                </value>
            </property>
            </configuration>
            EOF

{%if sparkUse %}
            echo "##### 02.spark setting start ###########"
            #yum -y install nc

            masterRun=1
            while [[ masterRun -eq 1 ]]
            do
              echo "nc -z $master_address 7077"
              nc -z $master_address 7077
              masterRun=$?
              sleep 5
            done
            echo "master node active"

            sudo -i -u centos bash << EOF
            source ~/.bashrc
            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            sudo -- sh -c "echo hworker-{{worker}} >> /home/centos/spark/conf/slaves"
            {%- endfor %}
            /home/centos/spark/sbin/start-slave.sh 'spark://hmaster:7077'
            echo "##### 02.spark setting end ###########"
            EOF
{% endif %}

{% if hbaseUse %}
            sudo -i -u centos bash << EOF
            source ~/.bashrc
            echo "##### 03.zookeeper setting start ###########"
            mkdir /home/centos/zookeeper/tmp
            cp /home/centos/zookeeper/conf/zoo_sample.cfg /home/centos/zookeeper/conf/zoo.cfg
            sudo -- sh -c "echo dataDir=/home/centos/zookeeper/tmp >> /home/centos/zookeeper/conf/zoo.cfg"
            sudo -- sh -c "echo server.1=hmaster:2888:3888 >> /home/centos/zookeeper/conf/zoo.cfg"
            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            sudo -- sh -c "echo server.{{server}}=hworker-{{worker}}:2888:3888 >> /home/centos/zookeeper/conf/zoo.cfg"
            {%- endfor %}
            echo "{{server}}" > /home/centos/zookeeper/tmp/myid
            chown centos:centos /home/centos/zookeeper/tmp/myid
            chmod 777 /home/centos/zookeeper/tmp/myid
            EOF
            sudo -i -u centos bash << EOF
            source ~/.bashrc
            /home/centos/zookeeper/bin/zkServer.sh start
            echo "##### 03.zookeeper setting end ###########"
            EOF


            echo "##### 04.hbase setting start ###########"
            VAR1=$(cat <<EOF
            <?xml version="1.0"?>
            <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
            <configuration>
                <property>
                    <name>hbase.rootdir</name>
                    <value>hdfs://hmaster:9000/hbase</value>
                </property>
                <property>
                    <name>hbase.cluster.distributed</name>
                    <value>true</value>
                </property>
                <property>
                    <name>hbase.zookeeper.quorum</name>
                    <value>hmaster{%- for worker in range(1,pworker) %}{% set server = worker + 1 %},hworker-{{worker}}{%- endfor %}</value>
                </property>
                <property>
                    <name>dfs.replication</name>
                    <value>3</value>
                </property>
                <property>
                  <name>hbase.unsafe.stream.capability.enforce</name>
                  <value>false</value>
                </property>
                <property>
                    <name>hbase.zookeeper.property.clientPort</name>
                    <value>2181</value>
                </property>
            </configuration>
            EOF
            )

            cat <<EOF> /home/centos/hbase/conf/hbase-site.xml
            ${VAR1}
            EOF

            chown centos:centos /home/centos/hbase/conf/hbase-site.xml

            cat <<EOF> /home/centos/hbase/conf/regionservers
            hmaster
            {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
            hworker-{{worker}}
            {%- endfor %}
            EOF

            chown centos:centos /home/centos/hbase/conf/regionservers

            cat <<EOF>> /home/centos/hbase/conf/hbase-env.sh
            export HBASE_MANAGES_ZK=false
            export HBASE_PID_DIR=/home/centos/hbase/pid
            EOF

            echo "##### 04.hbase setting end ###########"
{% endif %}



  {%- endfor %}

  server1:
    type: OS::Nova::Server
    properties:
      flavor: { get_param: master_flavor }
      image: { get_param: image }
      availability_zone: { get_param: availability_zone }
      networks:
        - port: { get_resource: server1_port }
      key_name: { get_param: key_name}
      user_data_format: RAW
      user_data:
        get_resource: init_config1

  {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
  server{{server}}:
    type: OS::Nova::Server
    properties:
      flavor: { get_param: worker_flavor }
      image: { get_param: image }
      availability_zone: { get_param: availability_zone }
      networks:
        - port: { get_resource: server{{server}}_port }
      key_name: { get_param: key_name}
      user_data_format: RAW
      user_data:
        get_resource: init_config{{server}}
  {%- endfor %}

outputs:
  servers:
    value:
      - instance: { get_attr: [ server1, show ] }
        instancePort: { get_attr: [ server1_port, show ] }
      {%- for worker in range(1,pworker) %} {% set server = worker + 1 %}
      - instance: { get_attr: [ server{{server}}, show ] }
        instancePort: { get_attr: [ server{{server}}_port, show ] }
      {%- endfor %}
